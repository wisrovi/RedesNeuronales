{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisrovi/RedesNeuronales/blob/master/07MAIR-WilliamSteveRodriguezVillamizar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqqRVNReQKkT",
        "colab_type": "text"
      },
      "source": [
        "# 0. Nota sobre notebook (leer antes de ejecutar otra linea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ElxHm9ROsr6",
        "colab_type": "text"
      },
      "source": [
        "## 0.0. \n",
        "Tanto para el ejercicio de crear la red neuronal desde cero como para la red neuronal con transferencia de conocimiento se aumento el dataseet de datos con ImageGenerator en cuatro (4) veces el tamaño original [No se pudo aumentar más veces debido a que el entorno de ejecución por mi GPU no lo permitió], esto para que los modelos entrenados tuvieran más generalización en los datos y con esto tuviera mejor respuesta en los test y predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdeYny71dCab",
        "colab_type": "text"
      },
      "source": [
        "## 0.1.\n",
        "Antes de efectuar cualquier carga del programa se debe iniciar el sistema ejecutando todos los codigos del apartado 2. Iniciar Sistema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBMPWq1dCng",
        "colab_type": "text"
      },
      "source": [
        "## 0.2. \n",
        "Para evaluar la red Neuronal creada desde cero se puede ir al punto 3.3 Cargar Modelo Red Neuronal Guardado (Nueva red neuronal desde cero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF3xoyEWdCsO",
        "colab_type": "text"
      },
      "source": [
        "## 0.3.\n",
        "Para evaluar el modelo por transferencia de conocimiento puede ir directamente al apartado 4.5. Cargar Modelo Red Neuronal Guardado (Transferencia conocimiento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOAz7yDngjmy",
        "colab_type": "text"
      },
      "source": [
        "## 0.4.\n",
        "El Base Folder se puede modificar en el apartado 2.2. Conexion con Google y Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOeT2G9KOffA",
        "colab_type": "text"
      },
      "source": [
        "# 1. Bibliografia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__eVaqBTw3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#urlArchivos = \"https://drive.google.com/drive/folders/1w2w5dAF269C646RBwwU33YLNUG4JRfh9?usp=sharing\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTrQGtyJQNaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjFtuL8AMOG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/jbagnato/machine-learning\n",
        "#https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#cnn\n",
        "#https://www.datacamp.com/community/blog/keras-cheat-sheet\n",
        "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
        "#https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
        "#https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "#https://www.aprendemachinelearning.com/clasificacion-de-imagenes-en-python/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AS0xQFPxgrA",
        "colab_type": "text"
      },
      "source": [
        "# 2. Iniciar Sistema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMLXo3q98M3S",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Importar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F6gZxIS7Kyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#instalo las librerias necesarias\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "#importo las librerias que se van a necesitar\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import expand_dims\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import to_categorical #para que las salidas queden parametrizadas en binario\n",
        "\n",
        "from sklearn.metrics import classification_report #para ver parametros \n",
        "\n",
        "from keras.applications.inception_v3 import decode_predictions #para ver varios items de prediccion\n",
        "\n",
        "#para autoescalar la imagen al tamaño requerido por la red a reentrenar\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "#Incrementar el número de ejemplos para evitar overfitting (junto con dropout)\n",
        "#Generar datos a partir de los presentes, a través de transformaciones\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "# Para las librerias para la red neuronal\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#callback para mejorar los entrenamientos\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAiLv5Xp8BBN",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Conexion con Google y Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_BsT13NeVYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiJJMYSeqTR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################\n",
        "BASE_FOLDER = '/content/gdrive/My Drive/Master IA/Redes Neuronales/'\n",
        "###################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbb2hnaUtniZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#le indicamos al colaboratory que las importaciones de librerias propias se haran tambien desde el directorio base\n",
        "import sys\n",
        "sys.path.append(BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O_gtPMX8G0L",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Importar Librerias propias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fM3bqw1unIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ModeloExterno import ModeloExterno"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVmc76dP7v2k",
        "colab_type": "text"
      },
      "source": [
        "## 2.4. Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9QOVrN_7ejl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def getRam_y_Gpu(imprimir=False):\n",
        "  process = psutil.Process(os.getpid())\n",
        "  ram_available = psutil.virtual_memory().available\n",
        "  ram_disponible = humanize.naturalsize( ram_available  )\n",
        "  gpu_disponible = gpu.memoryFree\n",
        "  if imprimir:\n",
        "      print(\"Gen RAM Free: \" + ram_disponible, \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "      print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu_disponible, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "  ram_available = ram_available / 1000000000\n",
        "  ram_available = round(ram_available, 2)\n",
        "  return (ram_available, gpu_disponible)\n",
        "\n",
        "#Algunas funciones utiles\n",
        "def plot_image(img, title=\"\"):\n",
        "    #plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    #plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def convertLabelsToNumbers(y_train):\n",
        "    # Transformando las labels de texto a valores numéricos\n",
        "    y = np.unique(y_train)\n",
        "    mapping = { key : value for key,value in zip(y,range(len(y)))}\n",
        "    processed_y = np.array([mapping[i] for i in y_train])\n",
        "    #print(len(mapping))\n",
        "    return processed_y\n",
        "\n",
        "def DividirDatos_Train_Test_Predic(x, y, porcentaje=0.25, randomDiv=50):\n",
        "    print(\"Datos para división recibidos\")\n",
        "\n",
        "    # dividir los datos entre training, test y predic\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        x_train_all, processed_y, \n",
        "        test_size=porcentaje, \n",
        "        random_state=randomDiv)\n",
        "    print(\"División todo el dataset en: train y test completa\")\n",
        "\n",
        "    X_test, X_predic, y_test, y_predic = train_test_split(\n",
        "        X_test, y_test, \n",
        "        test_size=porcentaje, \n",
        "        random_state=randomDiv)\n",
        "    print(\"División dataset test en: test y predict completa\")\n",
        "    \n",
        "    #Hacemos el One-hot Encoding\n",
        "    train_Y_one_hot = to_categorical(y_train)\n",
        "    test_Y_one_hot = to_categorical(y_test)\n",
        "    predic_Y_one_hot = to_categorical(y_predic)\n",
        "    print(\"Conversión de salidas en categorias completa\")\n",
        "\n",
        "    return (X_train, train_Y_one_hot), (X_test, test_Y_one_hot), (X_predic, predic_Y_one_hot)\n",
        "\n",
        "def plot_history(history):\n",
        "    # list all data in history\n",
        "    print(history.history.keys())\n",
        "    # summarize history for accuracy\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def plot_pred(pred):\n",
        "    plt.figure(figsize=(8, 2))\n",
        "    classes = [c[1] for c in pred]\n",
        "    probas = [c[2] for c in pred]\n",
        "    y_pos = np.arange(len(classes))\n",
        "    plt.barh(y_pos, probas, align='center')\n",
        "    plt.yticks(y_pos, classes)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xlabel('Probability')\n",
        "    plt.xlim(0, 1)\n",
        "\n",
        "def DefineCallback(nameFileIfSave): #guardar el mejor modelo w.r.t en val_losses\n",
        "    \"\"\"\n",
        "    Agradecimientos a Data Talks, \n",
        "    url: https://www.youtube.com/watch?v=Gl-N3xr5zLI\n",
        "    \"\"\"    \n",
        "    #EarlyStopping, detener el entrenamiento una vez que su pérdida comienza a aumentar \n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5, #argumento de patience representa el número de épocas antes de detenerse una vez que su pérdida comienza a aumentar (deja de mejorar). \n",
        "        min_delta=0,  #es un umbral para cuantificar una pérdida en alguna época como mejora o no. Si la diferencia de pérdida es inferior a min_delta , se cuantifica como no mejora. Es mejor dejarlo como 0 ya que estamos interesados ​​en cuando la pérdida empeora.\n",
        "        mode='auto')\n",
        "        \n",
        "    mcp_save = ModelCheckpoint(\n",
        "        nameFileIfSave + 'model-{acc:03f}-{val_acc:03f}.h5', \n",
        "        monitor='val_loss',\n",
        "        save_best_only=True, \n",
        "        mode='min')\n",
        "\n",
        "    #ReduceLROnPlateau, que si el entrenamiento no mejora tras unos epochs específicos, reduce el valor de learning rate del modelo\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss', \n",
        "        factor=0.1, \n",
        "        patience=5, \n",
        "        epsilon=1e-4, \n",
        "        mode='min')\n",
        "    \n",
        "    callbacks_list = [early_stop, reduce_lr, mcp_save]  \n",
        "    return callbacks_list\n",
        "\n",
        "#hago las conversiones a la imagen\n",
        "dataAumentationApliqued = False\n",
        "def ConverImageUsingImageDataGenerator(datagen, imagen, nombre, cantidadConversiones):\n",
        "    listaConversiones = []\n",
        "    listaEtiquetasCadaConversion = []\n",
        "    imagen4dimensiones = expand_dims(imagenConvertir, 0)\n",
        "    imagen3dimensiones = np.squeeze(imagen4dimensiones)\n",
        "    listaConversiones.append(convertNumpyToList(imagen3dimensiones))\n",
        "\n",
        "    iterator_datagen_train = datagen.flow(imagen4dimensiones, batch_size=1)\n",
        "\n",
        "    for i in range(cantidadConversiones):\n",
        "        batch = iterator_datagen_train.next()\n",
        "        image = np.squeeze(batch[0])\n",
        "        listaConversiones.append(convertNumpyToList(image))\n",
        "\n",
        "    for i in range(len(listaConversiones)):\n",
        "        listaEtiquetasCadaConversion.append(nombreImagen)\n",
        "    \n",
        "\n",
        "    return listaConversiones, listaEtiquetasCadaConversion\n",
        "\n",
        "def convertNumpyToList(imagenNumpy):\n",
        "    return list(imagenNumpy)\n",
        "\n",
        "def convertListoToNumpy(imagenList):\n",
        "    return array(imagenList)\n",
        "\n",
        "def getModelTransferLearning(baseModel):\n",
        "    model = models.Sequential()\n",
        "    model.add(baseModel)\n",
        "\n",
        "    model.add(Dropout(0.25)) #apagar un 25% de manera aleatoria para reducir la cantidad de parametros\n",
        "\n",
        "\n",
        "    model.add(\n",
        "        Conv2D(32,\n",
        "              kernel_size=(3, 3),\n",
        "              activation='relu',\n",
        "              padding='same',\n",
        "              input_shape=(128,128,3)\n",
        "              )\n",
        "        )\n",
        "\n",
        "    model.add( Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "\n",
        "    model.add(Dropout(0.25)) #apagar un 25% de manera aleatoria para reducir la cantidad de parametros\n",
        "\n",
        "    #para aplanar todas las capas\n",
        "    #esto se hace debido a que el modelo de VG16 nos da 4 dimensiones de salida, y con esto reducimos las dimensiones a dos: numero datos, numero clases\n",
        "    model.add(Flatten()) \n",
        "\n",
        "    # conectarlo a nueva parte densa\n",
        "    # Genero la capa final con la cantidad de neuronas segun la cantidad de opciones de clasificacion\n",
        "    model.add(Dense(nClasses, activation='softmax')) \n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # compilar el modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP0GR2j9KbaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_43c4mc_8XTF",
        "colab_type": "text"
      },
      "source": [
        "## 2.5. Importar Dataseet y clases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpNLDp__8daj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cargo los archivos de clases y las imagenes\n",
        "with open(BASE_FOLDER+\"pickle_all_images_df-002.pickle\", \"rb\") as input_file:\n",
        "    x_train_all = pickle.load(input_file)\n",
        "with open(BASE_FOLDER+\"pickle_all_classes.pickle\", \"rb\") as input_file:\n",
        "    y_train_all = pickle.load(input_file)\n",
        "\n",
        "number_of_classes = len(y_train_all)\n",
        "\n",
        "print(\"Entradas: \",x_train_all.shape)\n",
        "print(\"Salidas: \", number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAxLBVYlPrz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show a image\n",
        "plot_image(x_train_all[15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p687j8xyGGwE",
        "colab_type": "text"
      },
      "source": [
        "## 2.6. Repartir Datos entre train-test-predic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHDS5qguGSSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Cantidad imagenes: \", len(x_train_all))\n",
        "print(\"Cantidad etiquetas: \", len(y_train_all))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFVmLqSoGVHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_y = convertLabelsToNumbers(y_train_all)\n",
        "salidasCategoricas = to_categorical(processed_y)\n",
        "\n",
        "classesImageGenerator = np.unique(salidasCategoricas)\n",
        "nClassesImageGenerator = len(salidasCategoricas[1])\n",
        "print(\"Cantidad de categorias en las clases\",nClassesImageGenerator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKdigd_qGaBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagen = 7\n",
        "plot_image(x_train_all[imagen])\n",
        "print(processed_y[imagen], y_train_all[imagen])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afqatsW5GaFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = np.unique(processed_y)\n",
        "nClasses = len(classes)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test), (X_predic, y_predic) = DividirDatos_Train_Test_Predic(x_train_all, processed_y)\n",
        "\n",
        "print(\"Training (66.98%)\") \n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print() \n",
        "print(\"Test (22.1%)\") \n",
        "print(\"X_test\", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "print()\n",
        "print(\"Predict (10.89%)\") \n",
        "print(\"X_predic\", X_predic.shape)\n",
        "print(\"y_predic\", y_predic.shape)\n",
        "\n",
        "print()\n",
        "if y_predic.shape[1] == y_test.shape[1] and y_test.shape[1] == y_train.shape[1]:\n",
        "    print(\"Distribución correcta\")\n",
        "else:\n",
        "    print(\"Fallo en la distribución\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knojuCo1O9ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_all = x_train_all\n",
        "y_all = train_Y_one_hot = to_categorical(processed_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ih72Coy6Jis",
        "colab_type": "text"
      },
      "source": [
        "## 2.7. Aumentar el set de datos con DataGenerator (Opcional pero mejora los modelos cuando se utiliza)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHxbyzfq6PMV",
        "colab_type": "text"
      },
      "source": [
        "### 2.7.1 Creando el modelo generador de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPlhv1W1GoOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creamos el datagen del ImageDataGenerator para definir que cambios podria tener la imagen original\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=25, # grados de rotacion aleatoria\n",
        "    width_shift_range=0.15, # fraccion del total (1) para mover la imagen\n",
        "    height_shift_range=0.15, # fraccion del total (1) para mover la imagen\n",
        "    shear_range=0.05, # deslizamiento\n",
        "    zoom_range=0.1, # rango de zoom\n",
        "    horizontal_flip=True, # girar las imagenes horizontalmente (eje vertical)\n",
        "    fill_mode='nearest', # como rellenar posibles nuevos pixeles\n",
        "    channel_shift_range=0.2 # cambios aleatorios en los canales de la imagen\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcndsS1SPIyi",
        "colab_type": "text"
      },
      "source": [
        "### 2.7.2.Aplicando el data aumentation en el dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh7scHI957Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cantidadConversiones = 2\n",
        "#probado y funcionando con valor de 4, pero se requiere una buena GPU\n",
        "#porque es facil superar la RAM maxima, y cuando se supera el colab ya no funciona\n",
        "\n",
        "\n",
        "\n",
        "#También se incluirá la imagen original (en la practica no se suele usar la imagen original, pero para tener un dataset más grande en esta oportunidad la incluiremos)\n",
        "\n",
        "\n",
        "if dataAumentationApliqued == False:\n",
        "    print(\"Cantidad imagenes iniciales: \", len(X_train))\n",
        "    print(\"Cantidad etiquetas iniciales: \", len(y_train))\n",
        "    print(\"Tipo datos iniciales: \", type(X_train))\n",
        "    listadoImagenes = []\n",
        "    listaEtiquetasImagen = []\n",
        "    for imagenProcesar in range(len(X_train)):    \n",
        "        imagenConvertir = X_train[imagenProcesar] #elijo la imagen a usar de todo el dataset\n",
        "        nombreImagen = y_train[imagenProcesar]\n",
        "        listaConversiones, listaEtiquetasCadaConversion = ConverImageUsingImageDataGenerator(datagen, imagenConvertir, nombreImagen, cantidadConversiones-1)\n",
        "        #añado las conversiones a la lista con append\n",
        "        for i in range(len(listaConversiones)):\n",
        "            listadoImagenes.append(listaConversiones[i])\n",
        "            listaEtiquetasImagen.append(listaEtiquetasCadaConversion[i])\n",
        "\n",
        "    #convierto la lista nuevamente a numpy para entregarla a los modelos\n",
        "    X_train = convertListoToNumpy(listadoImagenes)\n",
        "    y_train = convertListoToNumpy(listaEtiquetasImagen)\n",
        "    print()\n",
        "    print(\"Cantidad imagenes finales: \", len(X_train))\n",
        "    print(\"Cantidad etiquetas finales: \", len(y_train))\n",
        "    print(\"Tipo datos finales: \", type(X_train))\n",
        "    dataAumentationApliqued = True\n",
        "else:\n",
        "    print(\"No se puede aplicar dataAumentation varias veces, si desea usarlo nuevamente, vuelva a reiniciar el colab (disponible en el menú de 'Entorno de ejecución').\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMRIan-TJWlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 4:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9xSeGyLH-qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for imagen in range(10):\n",
        "    titulo = str(processed_y[imagen]) + \" - \" + y_train_all[imagen]\n",
        "    plot_image(x_train_all[imagen], titulo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNtmqdYfOr3u",
        "colab_type": "text"
      },
      "source": [
        "## 2.8. Repartir datos en valid y train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlioQvaIPfdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 4:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1T6jylQyMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ2Km8ezOkMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, valid_X, train_label, valid_label = train_test_split(\n",
        "        X_train, y_train, \n",
        "        test_size=0.2, \n",
        "        random_state=10)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(valid_X.shape, valid_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtO9GFTXPZEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 4:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llpE8UA871kq",
        "colab_type": "text"
      },
      "source": [
        "# 3. Nueva Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhn4WJn8TjKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 3:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RbXG1dkNaM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nombreModeloCreado = \"wisrovi-nuevoModelo\"\n",
        "modelExtern = ModeloExterno(nombreModelo=nombreModeloCreado, rutaBase=BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPOLVRFpOSBW",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Modelo Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32aShwOn7QuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"********** Modelo *********\")\n",
        "#MaxPooling2D es una forma de reducir el número de parámetros en nuestro modelo deslizando un filtro de agrupación de 2x2 a través de la capa anterior \n",
        "#y tomando el máximo de los 4 valores en el filtro de 2x2.\n",
        "\n",
        "new_model = Sequential()\n",
        "new_model.add( Conv2D(32,  kernel_size=(3, 3), activation='relu',padding='same', input_shape=(128,128,3))  )\n",
        "new_model.add( Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "\n",
        "new_model.add( Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add( Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add( Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "\n",
        "new_model.add( Conv2D(96, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add( Conv2D(96, kernel_size=(3, 3), activation='relu', padding='same'  ) )\n",
        "new_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "\n",
        "new_model.add(Dropout(0.5)) #apagar un 50% de manera aleatoria para reducir la cantidad de parametros\n",
        "\n",
        "new_model.add(Flatten()) #para aplanar todas las capas\n",
        "new_model.add(Dense(96, activation='relu'))\n",
        "new_model.add(Dropout(0.1))\n",
        "new_model.add(Dense(96, activation='relu'))\n",
        "new_model.add(Dense(128, activation='relu'))\n",
        "new_model.add(Dropout(0.5))\n",
        "new_model.add(Dense(nClasses, activation='softmax')) #Genero la capa final con la cantidad de neuronas segun la cantidad de opciones de clasificacion\n",
        "\n",
        "new_model.summary()\n",
        "\n",
        "new_model.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "modelExtern.GuardarModelo(new_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llchrJsgXXfH",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIjNMxQL7Qzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Entreno el modelo\n",
        "numeroEntrenamientos = 50 #Al final de cada entrenamiento guardo los mejores pesos\n",
        "numeroEpocas = 11  #ciclos en los cuales evaluo los datos de entrenamiento para hallar los mejores pesos\n",
        "oldModel = None\n",
        "oldAccuaricy = 0\n",
        "conteoFallosEncontrarUnBuenModelo = 0\n",
        "for i in range(numeroEntrenamientos):     \n",
        "    print()   \n",
        "    print()\n",
        "    print(\"Entrenamiento \" + str(i + 1))\n",
        "\n",
        "    history = new_model.fit(\n",
        "        train_X, train_label, \n",
        "        batch_size=32, # cantidad de imágenes que se toman a la vez en memoria\n",
        "        epochs=numeroEpocas, \n",
        "        verbose=1,\n",
        "  \n",
        "        validation_data=(valid_X, valid_label),\n",
        "        callbacks=DefineCallback(nombreModeloCreado)\n",
        "        )\n",
        "        \n",
        "    plot_history(history)\n",
        "    \n",
        "    test_eval = new_model.evaluate(X_test, y_test, verbose=1)\n",
        "    print('Test loss:', test_eval[0])\n",
        "    print('Test accuracy:', test_eval[1])\n",
        "\n",
        "    if oldAccuaricy < test_eval[1]:\n",
        "        #Buscamos que haya mejora en el modelo, si hay mejora, guardamos el modelo\n",
        "        oldAccuaricy = test_eval[1]\n",
        "        modelExtern.GuardarPesosModelo()\n",
        "        oldModel = new_model\n",
        "        conteoFallosEncontrarUnBuenModelo = 0\n",
        "    else:\n",
        "        #Buscamos que el modelo tenga mejora en por lo menos 3 intentos, si supera tres intentos de entrenamiento sin mejora, se cancela el entrenamiento\n",
        "        conteoFallosEncontrarUnBuenModelo += 1\n",
        "        print(\"No se ha encontrado mejora al modelo, por lo cual se conservan el modelo anterior.\")\n",
        "        new_model = oldModel\n",
        "        if conteoFallosEncontrarUnBuenModelo > 3:\n",
        "            break\n",
        "    print(\"***************\")    \n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2M6jYjDP0Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#valido el modelo\n",
        "test_eval = new_model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMBVJgXmSs6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelExtern.GuardarPesosModelo()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afFipdWhTq01",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Cargar Modelo Red Neuronal Guardado (Nueva red neuronal desde cero)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKMoPfRTvNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modeloCargado = modelExtern.CargarModeloGuardado(False)\n",
        "modeloCargado.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KKfHbGUU3fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"*********************************************************************\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*                      Modelo Creado desde cero                     *\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*********************************************************************\")\n",
        "print()\n",
        "print()\n",
        "\n",
        "#valido el modelo\n",
        "test_eval = modeloCargado.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 2\n",
        "test_eval = modeloCargado.evaluate(X_predic, y_predic, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 3\n",
        "test_eval = modeloCargado.evaluate(x_all, y_all, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tAfR_p0LUz-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Reentrenar un modelo de ImageNet (usando VG16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9MdI0dWTgky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 3:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5S5OwPcNnMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nombreModeloTransferencia = \"wisrovi-transferLearning\"\n",
        "modeloTrasnferenciaConocimiento = ModeloExterno(nombreModelo=nombreModeloTransferencia, rutaBase=BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDOpf9aWLau3",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Cargar Modelo ImageNet VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ43mQRW7Qpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16, VGG19, ResNet50, \n",
        "#Xception, InceptionV3, InceptionResNetV2, \n",
        "#MobileNetV2, DenseNet, RasNet\n",
        "\n",
        "\n",
        "#https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "from keras.applications import VGG16 \n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                 include_top=False, # Si se deben incluir o no las capas de salida originales del modelo\n",
        "                 input_shape=(128,128,3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvOa4eFPsyI3",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Descongelar unas capas del Modelo ImageNet para reentrenarlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaKIld5mslEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "congelarTodoModeloImagenet = False\n",
        "if congelarTodoModeloImagenet:\n",
        "  conv_base.trainable = False\n",
        "else:\n",
        "  # Freeze the layers except the last 5 layers\n",
        "  cantidadCapasFinalesDescongelar = 5\n",
        "  for layer in conv_base.layers[:-cantidadCapasFinalesDescongelar]:\n",
        "      layer.trainable = False\n",
        "      pass\n",
        "\n",
        "  # Check the trainable status of the individual layers\n",
        "  for layer in conv_base.layers:\n",
        "      pass\n",
        "      print(layer, layer.trainable)\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx926sqBLk0z",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Crear nuestro modelo e incluirle el modelo de imageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5soqPRWlDcZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = getModelTransferLearning(conv_base)\n",
        "\n",
        "modeloTrasnferenciaConocimiento.GuardarModelo(pre_trained_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QVfy9R-RleC",
        "colab_type": "text"
      },
      "source": [
        "## 4.4. Entrenar Modelo Con conocimiento Transferido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EBapwPcQF5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Entreno el modelo\n",
        "\n",
        "#Al final de cada entrenamiento guardo los mejores pesos\n",
        "numeroEntrenamientos = 30\n",
        "\n",
        "#ciclos en los cuales evaluo los datos de entrenamiento para hallar los mejores pesos\n",
        "numeroEpocas = 15\n",
        "\n",
        "#ver datos entrenamiento\n",
        "print(\"Int: \", train_X.shape)\n",
        "print(\"Out: \", train_label.shape)\n",
        "\n",
        "oldModel = None\n",
        "oldAccuaricy = 0\n",
        "conteoFallosEncontrarUnBuenModelo = 0\n",
        "for i in range(numeroEntrenamientos):     \n",
        "    print()   \n",
        "    print()\n",
        "    print(\"Entrenamiento \" + str(i + 1))\n",
        "\n",
        "    history = pre_trained_model.fit(\n",
        "        train_X, train_label, \n",
        "        batch_size=64, # cantidad de imágenes que se toman a la vez en memoria\n",
        "        epochs=numeroEpocas,        \n",
        "        verbose=1,\n",
        "        validation_data=(valid_X, valid_label),\n",
        "        callbacks=DefineCallback(nombreModeloTransferencia)\n",
        "        )\n",
        "        \n",
        "    plot_history(history)   \n",
        "\n",
        "    test_eval = pre_trained_model.evaluate(X_test, y_test, verbose=1)\n",
        "    print('Test loss:', test_eval[0])\n",
        "    print('Test accuracy:', test_eval[1])\n",
        "\n",
        "    if oldAccuaricy < test_eval[1]:\n",
        "        #Buscamos que haya mejora en el modelo, si hay mejora, guardamos el modelo\n",
        "        oldAccuaricy = test_eval[1]\n",
        "        modeloTrasnferenciaConocimiento.GuardarPesosModelo()\n",
        "        oldModel = pre_trained_model\n",
        "        conteoFallosEncontrarUnBuenModelo = 0\n",
        "    else:\n",
        "        #Buscamos que el modelo tenga mejora en por lo menos 3 intentos, si supera tres intentos de entrenamiento sin mejora, se cancela el entrenamiento\n",
        "        conteoFallosEncontrarUnBuenModelo += 1\n",
        "        pre_trained_model = oldModel\n",
        "        print(\"No se ha encontrado mejora al modelo, por lo cual se conservan el modelo anterior.\")\n",
        "        if conteoFallosEncontrarUnBuenModelo > 3:\n",
        "            break\n",
        "    print(\"***************\")    \n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0quccTuqXCJ",
        "colab_type": "text"
      },
      "source": [
        "## 4.5. Cargar Modelo Red Neuronal Guardado (Transferencia conocimiento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilio5dT7TYtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modeloCargadoTransferenciaConocimiento = modeloTrasnferenciaConocimiento.CargarModeloGuardado(False)\n",
        "modeloCargadoTransferenciaConocimiento.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOLwmbY-TKdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"*********************************************************************\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*           Modelo basado en transferencia de conocimiento          *\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*********************************************************************\")\n",
        "print()\n",
        "print()\n",
        "\n",
        "#valido el modelo\n",
        "test_eval = modeloCargadoTransferenciaConocimiento.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 2\n",
        "test_eval = modeloCargadoTransferenciaConocimiento.evaluate(X_predic, y_predic, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 3\n",
        "test_eval = modeloCargadoTransferenciaConocimiento.evaluate(x_all, y_all, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRwX24RG7DkE",
        "colab_type": "text"
      },
      "source": [
        "# 5. Reentrenar un modelo de ImageNet (usando xxxx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pZs8oso7NHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ramColab, GpuColab = getRam_y_Gpu(False)\n",
        "if ramColab < 3:\n",
        "    print(\"La Ram disponible no es suficiente para los entrenamientos de la red neuronal.\")\n",
        "else:\n",
        "    getRam_y_Gpu(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRgROhc77QTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nombreModeloTransferencia2 = \"wisrovi-transferLearning-2\"\n",
        "modeloTrasnferenciaConocimiento2 = ModeloExterno(nombreModelo=nombreModeloTransferencia2, rutaBase=BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlW7JWOw7Yub",
        "colab_type": "text"
      },
      "source": [
        "## 5.1. Cargar Modelo ImageNet MobileNetV2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKmKyTbr8XDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16, VGG19, ResNet50, \n",
        "#Xception, InceptionV3, InceptionResNetV2, \n",
        "#MobileNetV2, DenseNet, RasNet\n",
        "\n",
        "\n",
        "#https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "from keras.applications import MobileNetV2 \n",
        "conv_base = MobileNetV2(weights='imagenet',\n",
        "                 include_top=False, # Si se deben incluir o no las capas de salida originales del modelo\n",
        "                 input_shape=(128,128,3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfmubqX57bHb",
        "colab_type": "text"
      },
      "source": [
        "## 5.2. Descongelar unas capas del Modelo ImageNet para reentrenarlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PPARw9m8Xej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "congelarTodoModeloImagenet = False\n",
        "if congelarTodoModeloImagenet:\n",
        "  conv_base.trainable = False\n",
        "else:\n",
        "  # Freeze the layers except the last 5 layers\n",
        "  cantidadCapasFinalesDescongelar = 5\n",
        "  for layer in conv_base.layers[:-cantidadCapasFinalesDescongelar]:\n",
        "      layer.trainable = False\n",
        "      pass\n",
        "\n",
        "  # Check the trainable status of the individual layers\n",
        "  for layer in conv_base.layers:\n",
        "      pass\n",
        "      print(layer, layer.trainable)\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FWoV5dU7bkN",
        "colab_type": "text"
      },
      "source": [
        "## 5.3. Crear nuestro modelo e incluirle el modelo de imageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEqDpCeX8X8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model_2 = getModelTransferLearning(conv_base)\n",
        "\n",
        "modeloTrasnferenciaConocimiento2.GuardarModelo(pre_trained_model_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSXdOR407b5P",
        "colab_type": "text"
      },
      "source": [
        "## 5.4. Entrenar Modelo Con conocimiento Transferido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJuQfuPA8YZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Entreno el modelo\n",
        "\n",
        "#Al final de cada entrenamiento guardo los mejores pesos\n",
        "numeroEntrenamientos = 30\n",
        "\n",
        "#ciclos en los cuales evaluo los datos de entrenamiento para hallar los mejores pesos\n",
        "numeroEpocas = 15\n",
        "\n",
        "#ver datos entrenamiento\n",
        "print(\"Int: \", train_X.shape)\n",
        "print(\"Out: \", train_label.shape)\n",
        "\n",
        "oldModel = None\n",
        "oldAccuaricy = 0\n",
        "conteoFallosEncontrarUnBuenModelo = 0\n",
        "for i in range(numeroEntrenamientos):     \n",
        "    print()   \n",
        "    print()\n",
        "    print(\"Entrenamiento \" + str(i + 1))\n",
        "\n",
        "    history = pre_trained_model_2.fit(\n",
        "        train_X, train_label, \n",
        "        batch_size=32, # cantidad de imágenes que se toman a la vez en memoria\n",
        "        epochs=numeroEpocas,        \n",
        "        verbose=1,\n",
        "        validation_data=(valid_X, valid_label),\n",
        "        callbacks=DefineCallback(nombreModeloTransferencia2)\n",
        "        )\n",
        "        \n",
        "    plot_history(history)   \n",
        "\n",
        "    test_eval = pre_trained_model_2.evaluate(X_test, y_test, verbose=1)\n",
        "    print('Test loss:', test_eval[0])\n",
        "    print('Test accuracy:', test_eval[1])\n",
        "\n",
        "    if oldAccuaricy < test_eval[1]:\n",
        "        #Buscamos que haya mejora en el modelo, si hay mejora, guardamos el modelo\n",
        "        oldAccuaricy = test_eval[1]\n",
        "        modeloTrasnferenciaConocimiento2.GuardarPesosModelo()\n",
        "        oldModel = pre_trained_model_2\n",
        "        conteoFallosEncontrarUnBuenModelo = 0\n",
        "    else:\n",
        "        #Buscamos que el modelo tenga mejora en por lo menos 3 intentos, si supera tres intentos de entrenamiento sin mejora, se cancela el entrenamiento\n",
        "        conteoFallosEncontrarUnBuenModelo += 1\n",
        "        pre_trained_model_2 = oldModel\n",
        "        print(\"No se ha encontrado mejora al modelo, por lo cual se conservan el modelo anterior.\")\n",
        "        if conteoFallosEncontrarUnBuenModelo > 3:\n",
        "            break\n",
        "    print(\"***************\")    \n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Riddrhya7cbo",
        "colab_type": "text"
      },
      "source": [
        "## 5.5. Cargar Modelo Red Neuronal Guardado (Transferencia conocimiento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cQ5O6oy8Y78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modeloCargadoTransferenciaConocimiento2 = modeloTrasnferenciaConocimiento2.CargarModeloGuardado(False)\n",
        "modeloCargadoTransferenciaConocimiento2.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSE8KsYd8jSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"*********************************************************************\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*          Modelo basado en transferencia de conocimiento 2         *\")\n",
        "print(\"*                                                                   *\")\n",
        "print(\"*********************************************************************\")\n",
        "print()\n",
        "print()\n",
        "\n",
        "#valido el modelo\n",
        "test_eval = modeloCargadoTransferenciaConocimiento2.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 2\n",
        "test_eval = modeloCargadoTransferenciaConocimiento2.evaluate(X_predic, y_predic, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()\n",
        "\n",
        "#valido el modelo 3\n",
        "test_eval = modeloCargadoTransferenciaConocimiento2.evaluate(x_all, y_all, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy: %s %%' %( round(test_eval[1]*100, 2)))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEVXhpUYj5J8",
        "colab_type": "text"
      },
      "source": [
        "# 6. Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE0jz2pAj-oL",
        "colab_type": "text"
      },
      "source": [
        "Al usar la transferencia de conocimiento es más facil alcanzar un modelo de clasificacion óptimo para el objetivo propuesto en pocas epocas de reentrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgxTr9twkSS8",
        "colab_type": "text"
      },
      "source": [
        "Al implementar un aumento de dataset con imageDataGenerator los modelos se entrenan con datos mas generales y esto logra que el modelo sea mas eficiente al predecir datos que no se mostraron durante el entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LguJlC7gkSY5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pRDp79PkSQT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}