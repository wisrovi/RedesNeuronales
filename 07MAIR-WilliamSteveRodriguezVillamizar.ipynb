{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisrovi/RedesNeuronales/blob/master/07MAIR-WilliamSteveRodriguezVillamizar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaCxr11koF2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__eVaqBTw3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#urlArchivos = \"https://drive.google.com/drive/folders/1w2w5dAF269C646RBwwU33YLNUG4JRfh9?usp=sharing\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_BsT13NeVYg",
        "colab_type": "code",
        "outputId": "0e47175c-e5dc-4749-efe5-2e53f4d49fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiJJMYSeqTR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################################################\n",
        "BASE_FOLDER = '/content/drive/My Drive/Master IA/Redes Neuronales/'\n",
        "BASE_FOLDER = '/content/gdrive/My Drive/Master IA/Redes Neuronales/'\n",
        "###################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbb2hnaUtniZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#le indicamos al colaboratory que las importaciones de librerias propias se haran tambien desde el directorio base\n",
        "import sys\n",
        "sys.path.append(BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fM3bqw1unIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ModeloExterno import ModeloExterno\n",
        "modelExtern = ModeloExterno(nombreModelo=\"wisrovi\", rutaBase=BASE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teppWRU9mGrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls \"/content/gdrive/My Drive/Master IA/Redes Neuronales/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBilp6Hlc4v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importo las librerias que se van a necesitar\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import to_categorical #para que las salidas queden parametrizadas en binario\n",
        "\n",
        "from sklearn.metrics import classification_report #para ver parametros \n",
        "\n",
        "from keras.applications.inception_v3 import decode_predictions #para ver varios items de prediccion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxs99GUUvOaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#para autoescalar la imagen al tamaño requerido por la red a reentrenar\n",
        "from keras.applications.inception_v3 import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGwc7RQZciJp",
        "colab_type": "code",
        "outputId": "b9ccedd8-9d48-4081-bf47-75e4e22ed962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Cargo los archivos de clases y las imagenes\n",
        "with open(BASE_FOLDER+\"pickle_all_images_df-002.pickle\", \"rb\") as input_file:\n",
        "    x_train_all = pickle.load(input_file)\n",
        "with open(BASE_FOLDER+\"pickle_all_classes.pickle\", \"rb\") as input_file:\n",
        "    y_train_all = pickle.load(input_file)\n",
        "\n",
        "number_of_classes = len(y_train_all)\n",
        "\n",
        "print(\"Entradas: \",x_train_all.shape)\n",
        "print(\"Salidas: \", number_of_classes)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entradas:  (9145, 128, 128, 3)\n",
            "Salidas:  9145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbemf1XLvlNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Algunas funciones utiles\n",
        "def plot_image(img, title=\"\"):\n",
        "    #plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    #plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def convertLabelsToNumbers(y_train):\n",
        "    # Transformando las labels de texto a valores numéricos\n",
        "    y = np.unique(y_train)\n",
        "    mapping = { key : value for key,value in zip(y,range(len(y)))}\n",
        "    processed_y = np.array([mapping[i] for i in y_train])\n",
        "    print(len(mapping))\n",
        "    return processed_y\n",
        "\n",
        "def DividirDatos_Train_Test_Predic(x, y, porcentaje=0.25, randomDiv=52):\n",
        "    # dividir los datos entre training, test y predic\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        x_train_all, processed_y, \n",
        "        test_size=porcentaje, \n",
        "        random_state=randomDiv)\n",
        "\n",
        "    X_test, X_predic, y_test, y_predic = train_test_split(\n",
        "        X_test, y_test, \n",
        "        test_size=porcentaje, \n",
        "        random_state=randomDiv)\n",
        "    \n",
        "    #Hacemos el One-hot Encoding\n",
        "    train_Y_one_hot = to_categorical(y_train)\n",
        "    test_Y_one_hot = to_categorical(y_test)\n",
        "    predic_Y_one_hot = to_categorical(y_predic)\n",
        "\n",
        "    return (X_train, train_Y_one_hot), (X_test, test_Y_one_hot), (X_predic, predic_Y_one_hot)\n",
        "\n",
        "def plot_history(history):\n",
        "    # list all data in history\n",
        "    print(history.history.keys())\n",
        "    # summarize history for accuracy\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def plot_pred(pred):\n",
        "    plt.figure(figsize=(8, 2))\n",
        "    classes = [c[1] for c in pred]\n",
        "    probas = [c[2] for c in pred]\n",
        "    y_pos = np.arange(len(classes))\n",
        "    plt.barh(y_pos, probas, align='center')\n",
        "    plt.yticks(y_pos, classes)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xlabel('Probability')\n",
        "    plt.xlim(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTFcHm3fG34g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e9a89bd-3865-43cc-fa5a-c9509b26d111"
      },
      "source": [
        "imagen = 250\n",
        "\n",
        "# show image\n",
        "#plot_image(x_train_all[imagen])\n",
        "\n",
        "processed_y = convertLabelsToNumbers(y_train_all)\n",
        "print(processed_y[imagen], y_train_all[imagen])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102\n",
            "6 airplanes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqu3l8mH1t8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "730f9040-8232-40cf-e1ff-b4d1244020f8"
      },
      "source": [
        "classes = np.unique(processed_y)\n",
        "nClasses = len(classes)\n",
        "print(\"Numero de clases diferenes:\", nClasses)\n",
        "print()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test), (X_predic, y_predic) = DividirDatos_Train_Test_Predic(x_train_all, processed_y)\n",
        "\n",
        "print(\"Training (66.98%)\") \n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print() \n",
        "print(\"Test (22.1%)\") \n",
        "print(\"X_test\", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "print()\n",
        "print(\"Predict (10.89%)\") \n",
        "print(\"X_predic\", X_predic.shape)\n",
        "print(\"y_predic\", y_predic.shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de clases diferenes: 102\n",
            "\n",
            "Training (66.98%)\n",
            "X_train (6858, 128, 128, 3)\n",
            "y_train (6858, 102)\n",
            "\n",
            "Test (22.1%)\n",
            "X_test (1715, 128, 128, 3)\n",
            "y_test (1715, 102)\n",
            "\n",
            "Predict (10.89%)\n",
            "X_predic (572, 128, 128, 3)\n",
            "y_predic (572, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Oo94tVPsN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creamos el Set de Entrenamiento y Validación\n",
        "#divido los datos de entrenamiento en dos, un 80% para el entrenamiento y otro 20% para validacion\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(\n",
        "    X_train, y_train, \n",
        "    test_size=0.1, random_state=43)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmLI0XOXyTKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "cae1bafc-bc81-437f-baf6-b28e0641ad85"
      },
      "source": [
        "print(\"********** Modelo *********\")\n",
        "\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "new_model = Sequential()\n",
        "new_model.add(\n",
        "    Conv2D(32,\n",
        "           kernel_size=(3, 3),\n",
        "           activation='relu',\n",
        "           padding='same',\n",
        "           input_shape=(128,128,3)\n",
        "           )\n",
        "    )\n",
        "new_model.add(Dense(128, activation='relu'))\n",
        "new_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "new_model.add(Dropout(0.5))\n",
        "\n",
        "new_model.add(Dense(120, activation='relu'))\n",
        "new_model.add(Dropout(0.25)) \n",
        "new_model.add(Dense(64, activation='relu'))\n",
        "new_model.add(Dense(64, activation='relu'))\n",
        "new_model.add(Flatten())\n",
        "new_model.add(Dense(64, activation='relu'))\n",
        "new_model.add(Dense(87, activation='relu'))\n",
        "new_model.add(Dropout(0.5)) \n",
        "new_model.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "new_model.summary()\n",
        "\n",
        "new_model.compile(optimizer='rmsprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** Modelo *********\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 128, 128, 32)      896       \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 128, 128, 128)     4224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 64, 64, 120)       15480     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64, 64, 120)       0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 64, 64, 64)        7744      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 64, 64, 64)        4160      \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 262144)            0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 64)                16777280  \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 87)                5655      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 102)               8976      \n",
            "=================================================================\n",
            "Total params: 16,824,415\n",
            "Trainable params: 16,824,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRocLV4cfXxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "51dd6787-9187-4415-a285-a185380cee75"
      },
      "source": [
        "for i in range(50):\n",
        "  #Entreno el modelo\n",
        "  history = new_model.fit(\n",
        "      train_X, train_label, \n",
        "      batch_size=64, # cantidad de imágenes que se toman a la vez en memoria\n",
        "      epochs=50,\n",
        "      verbose=1,\n",
        "      validation_data=(valid_X, valid_label)\n",
        "      )\n",
        "  modelExtern.GuardarModelo(new_model)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6172 samples, validate on 686 samples\n",
            "Epoch 1/50\n",
            "6172/6172 [==============================] - 11s 2ms/step - loss: 4.4100 - acc: 0.1267 - val_loss: 3.7233 - val_acc: 0.2012\n",
            "Epoch 2/50\n",
            "6172/6172 [==============================] - 9s 2ms/step - loss: 3.5936 - acc: 0.2575 - val_loss: 3.4366 - val_acc: 0.3017\n",
            "Epoch 3/50\n",
            "3136/6172 [==============>...............] - ETA: 4s - loss: 3.4267 - acc: 0.2969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-93091164eda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       )\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodelExtern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGuardarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m                 array_vals.append(\n\u001b[1;32m   2916\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2917\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n45M_9d_1-OH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "af3243ed-fa72-45cb-f992-33b20e0b87dc"
      },
      "source": [
        "#valido el modelo\n",
        "test_eval = new_model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1715/1715 [==============================] - 1s 607us/step\n",
            "Test loss: 3.1900285549831113\n",
            "Test accuracy: 0.3236151604541189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5soqPRWlDcZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c1E1xA1ety_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelExtern.GuardarModelo(new_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnwVXzQ9pqCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "3e470038-8603-4977-bdb0-9bec38a4f061"
      },
      "source": [
        "class ModeloExterno:\n",
        "    from keras.models import model_from_json\n",
        "    \n",
        "    nombreJson = \"model.json\"\n",
        "    nombrePesos = \"model.h5\"\n",
        "    def __init__(self, nombreModelo, rutaBase = \"\"):\n",
        "        self.nombreModelo = nombreModelo\n",
        "        self.rutaBase = rutaBase\n",
        "\n",
        "    def GuardarModelo(self, model):\n",
        "        try:\n",
        "            # serializar el modelo a JSON\n",
        "            model_json = model.to_json()\n",
        "            with open(self.rutaBase + self.nombreModelo + \"-\" + self.nombreJson, \"w\") as json_file:\n",
        "                json_file.write(model_json)\n",
        "                #print(\"Modelo guardado!\")\n",
        "            # serializar los pesos a HDF5\n",
        "            model.save_weights(self.rutaBase + self.nombreModelo + \"-\" + self.nombrePesos)\n",
        "            #print(\"Pesos Guardados!\")\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def CargarModeloGuardado(self, optimizacionDefault=False):\n",
        "        # cargar json\n",
        "        archivo = self.rutaBase + self.nombreModelo + \"-\" + self.nombreJson\n",
        "        json_file = open(archivo, 'r')\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        with open(self.rutaBase + self.nombreModelo + \"-\" + self.nombreJson, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            \n",
        "        #crear el modelo\n",
        "        loaded_model = self.model_from_json(loaded_model_json)\n",
        "        #print(\"Modelo Cargado!\")\n",
        "\n",
        "        # cargar pesos al nuevo modelo\n",
        "        archivo = self.rutaBase + self.nombreModelo + \"-\" + self.nombrePesos\n",
        "        loaded_model.load_weights(archivo)\n",
        "        print(\"Pesos Cargados!\")\n",
        "        \n",
        "        # Compilar modelo cargado y listo para usar.\n",
        "        if optimizacionDefault:\n",
        "            loaded_model.compile(optimizer='rmsprop',\n",
        "                        loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "            print(\"Modelo compilado!\")\n",
        "        return loaded_model\n",
        "\n",
        "modelExtern = ModeloExterno(nombreModelo=\"prueba\", rutaBase=BASE_FOLDER)\n",
        "modelExtern.GuardarModelo(new_model)\n",
        "modelExtern.CargarModeloGuardado(optimizacionDefault=True)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-aed83966d12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mmodelExtern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModeloExterno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnombreModelo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prueba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrutaBase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBASE_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmodelExtern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGuardarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodelExtern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCargarModeloGuardado\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizacionDefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-92-aed83966d12e>\u001b[0m in \u001b[0;36mCargarModeloGuardado\u001b[0;34m(self, optimizacionDefault)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#crear el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(\"Modelo Cargado!\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muncompiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             raise TypeError('the JSON object must be str, bytes or bytearray, '\n\u001b[0;32m--> 348\u001b[0;31m                             'not {!r}'.format(s.__class__.__name__))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not 'ModeloExterno'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-vg3-N3e88b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a478f9e9-55d3-44b1-9892-7c83d71159e2"
      },
      "source": [
        "modeloCArgado = modelExtern.CargarModeloGuardado(True)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No se pudo cargar el modelo.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb7E6WVUEC_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dato = preprocess_input(X_predic[50])\n",
        "dato = np.expand_dims(dato, axis=0) #añadir una dimension mas para que el modelo lo pueda evaluar\n",
        "#print(dato.shape)\n",
        "\n",
        "prediccion = new_model.predict(dato) #predecir\n",
        "#print(prediccion[0])\n",
        "\n",
        "ynew = new_model.predict_classes(X_predic)\n",
        "#print(ynew)\n",
        "for i in range(len(X_predic)):\n",
        "\t  #print(\"X=%s\" % (X_predic[i]))\n",
        "\t  print(\"Predicted=%s\" % (y_predic[i]))\n",
        "    #print(y_train_all[y_predic[i]])\n",
        "\n",
        "#print(decode_predictions(prediccion, top=5))\n",
        "#plot_pred()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wwlU5LUEC82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi1f3pOOEC6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2098oesf1-Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_WN8r8S1-Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4YRc2TJ1-Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAqmZ7qO1-KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDS22-sywTBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16, VGG19, ResNet50, \n",
        "#Xception, InceptionV3, InceptionResNetV2, \n",
        "#MobileNetV2, DenseNet, RasNet\n",
        "\n",
        "\n",
        "#https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "from keras.applications import VGG16 \n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                 include_top=False, # Si se deben incluir o no las capas de salida para el modelo\n",
        "                 input_shape=(128,128,3))\n",
        "\n",
        "congelarTodoModeloImagenet = False\n",
        "if congelarTodoModeloImagenet:\n",
        "  conv_base.trainable = False\n",
        "else:\n",
        "  # Freeze the layers except the last 4 layers\n",
        "  cantidadCapasFinalesDescongelar = 4\n",
        "  for layer in conv_base.layers[:-cantidadCapasFinalesDescongelar]:\n",
        "      layer.trainable = False\n",
        "      pass\n",
        "\n",
        "  # Check the trainable status of the individual layers\n",
        "  for layer in conv_base.layers:\n",
        "      pass\n",
        "      print(layer, layer.trainable)\n",
        "\n",
        "\n",
        "\n",
        "#conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fqw4Dd_wPWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "conv_base = InceptionV3(\n",
        "      weights='imagenet', \n",
        "      include_top=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v0q6FQ2e4Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = models.Sequential()\n",
        "pre_trained_model.add(conv_base)\n",
        "\n",
        "# conectarlo a nueva parte densa\n",
        "pre_trained_model.add(layers.Dense(number_of_classes, activation='relu'))\n",
        "pre_trained_model.add(layers.Dense(1, activation='relu'))\n",
        "\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# compilar el modelo\n",
        "pre_trained_model.compile(optimizer='rmsprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "#entrenar el modelo\n",
        "history = pre_trained_model.fit(X_train, y_train, epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reO75MTJSJkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,accuracy = pre_trained_model.evaluate(X_test_eval,y_test_eval)\n",
        "\n",
        "print('loss {} accuracy {}'.format(loss,accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l0Nbw7Gw_eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STXi_Hi2xw1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjjJEcdMyJpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "plot_image(x_train_all[250], y_train_all[250])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtYaSSuX4_lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"conjunto datos predecir: \", len(X_test_predic))\n",
        "cantidadPorcentajesMostrar = 5 #muestra los de mayor porcentaje"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pipfzpif48Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def predecir(model, dato):\n",
        "  dato = resize(dato, (299, 299), anti_aliasing=True)\n",
        "\n",
        "  dato = preprocess_input(dato)\n",
        "  dato = np.expand_dims(dato, axis=0) #añadir una dimension mas para que el modelo lo pueda evaluar\n",
        "\n",
        "  prediccion = model.predict(dato) #predecir\n",
        "  return decode_predictions(prediccion, top=cantidadPorcentajesMostrar)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4hV5zKw_hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dato_evaluar = X_predic[100]\n",
        "pred = predecir(conv_base, dato_evaluar)\n",
        "plot_image(dato_evaluar, \"Pred\")\n",
        "plot_pred(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_tE9oravtba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_test_predic[0].shape)\n",
        "print(type(X_test_predic[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYnztCIP2xs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nombreModeloGuardado = \"model.json\"\n",
        "nombrePesosGuardados = \"model.h5\"\n",
        "\n",
        "def GuardarModelo(model, archivoModelo, archivoPesos):\n",
        "    try:\n",
        "        # serializar el modelo a JSON\n",
        "        model_json = model.to_json()\n",
        "        with open(archivoModelo, \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "            print(\"Modelo guardado!\")\n",
        "        # serializar los pesos a HDF5\n",
        "        model.save_weights(archivoPesos)\n",
        "        print(\"Pesos Guardados!\")\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "GuardarModelo(conv_base, BASE_FOLDER + \"model.json\",  BASE_FOLDER + \"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_-08kYc3xEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "def CargarModeloGuardado(archivoModelo, archivoPesos):\n",
        "    # cargar json y crear el modelo\n",
        "    json_file = open(archivoModelo, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    print(\"Modelo Cargado!\")\n",
        "\n",
        "    # cargar pesos al nuevo modelo\n",
        "    loaded_model.load_weights(archivoPesos)\n",
        "    print(\"Pesos Cargados!\")\n",
        "    \n",
        "    # Compilar modelo cargado y listo para usar.\n",
        "    loaded_model.compile(optimizer='rmsprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "    print(\"Modelo compilado!\")\n",
        "    return loaded_model\n",
        "\n",
        "modeloCargado = CargarModeloGuardado(BASE_FOLDER + \"model.json\",  BASE_FOLDER + \"model.h5\")\n",
        "#modeloCargado.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L-9ANRW5EV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dato_evaluar = X_predic[150]\n",
        "pred = predecir(modeloCargado, dato_evaluar)\n",
        "plot_image(dato_evaluar, \"Pred\")\n",
        "plot_pred(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrPiv18D_YnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dato_evaluar = X_predic[350]\n",
        "pred = predecir(modeloCargado, dato_evaluar)\n",
        "\n",
        "from sklearn.metrics import classification_report \n",
        "scnn_report = classification_report(np.argmax(y_predic, axis=1), pred)  \n",
        "print(scnn_report) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpzVEtsbHHqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klRSJiF2HHn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGZ4nri-HHmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rnoy3yZHHko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnss6HzHHjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6EG2ziHHhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BSV4uNvHHdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XhDjV1HHHYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.aprendemachinelearning.com/clasificacion-de-imagenes-en-python/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}